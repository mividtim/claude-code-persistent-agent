#!/usr/bin/env python3
"""Semantic index for an agent's memory vault.

Builds a keyword-based semantic index of all markdown files in memory/.
Designed to be driven by a model subagent that generates summaries and
keywords for each file, then updates the index via the `update` command.

The index lives at memory/meta/semantic-index.json and supports search
by keyword overlap, structured JSON output for reranking, and miss
logging for evaluation.

Usage:
  # Scan vault â€” print files that need indexing
  python3 scripts/index-vault.py scan

  # Print a single file's content + hash (for the subagent to summarize)
  python3 scripts/index-vault.py file memory/some/note.md

  # Update index entry after subagent generates summary + keywords
  python3 scripts/index-vault.py update <path> <summary> <keywords-csv> [related-csv]

  # Search by keyword overlap
  python3 scripts/index-vault.py search <query>

  # Search with structured JSON output (for subagent reranking)
  python3 scripts/index-vault.py search-json <query>

  # Log a missed association (query didn't surface expected file)
  python3 scripts/index-vault.py miss <query> <expected-path> [reason]

  # Show miss log
  python3 scripts/index-vault.py misses

  # Show index stats
  python3 scripts/index-vault.py stats
"""

import glob
import hashlib
import json
import os
import sys
from datetime import datetime, timezone

# All paths are relative to the project root (where memory/ lives),
# not relative to this script or the plugin directory.
VAULT_DIR = 'memory'
INDEX_FILE = os.path.join(VAULT_DIR, 'meta', 'semantic-index.json')
MISS_LOG_FILE = os.path.join(VAULT_DIR, 'meta', 'miss-log.json')


def content_hash(text):
    """Short SHA-256 hash for change detection."""
    return hashlib.sha256(text.encode()).hexdigest()[:16]


def load_index():
    """Load index from disk, or return empty structure."""
    try:
        with open(INDEX_FILE, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {'version': 1, 'entries': {}}


def save_index(index):
    """Write index to disk, creating directories as needed."""
    os.makedirs(os.path.dirname(INDEX_FILE), exist_ok=True)
    with open(INDEX_FILE, 'w') as f:
        json.dump(index, f, indent=2)


def vault_files():
    """Find all markdown files in the vault."""
    return sorted(glob.glob(os.path.join(VAULT_DIR, '**', '*.md'), recursive=True))


# ---------------------------------------------------------------------------
# Commands
# ---------------------------------------------------------------------------

def cmd_scan():
    """Find files needing indexing. Prints info for a subagent to process."""
    index = load_index()
    files = vault_files()
    needs_indexing = []

    for fpath in files:
        with open(fpath, 'r') as f:
            text = f.read()
        h = content_hash(text)
        entry = index['entries'].get(fpath)
        if entry and entry.get('content_hash') == h:
            continue
        needs_indexing.append(fpath)
        print(f'NEEDS_INDEX: {fpath}')
        print(f'  hash: {h}')
        # Preview first 5 lines for context
        for line in text.split('\n')[:5]:
            print(f'  | {line}')
        print()

    if not needs_indexing:
        print('All files indexed and up to date.')
    else:
        print(f'\n{len(needs_indexing)} file(s) need indexing.')

    return needs_indexing


def cmd_file(fpath):
    """Print file contents and hash for a subagent to summarize."""
    if not os.path.isfile(fpath):
        print(f'Error: file not found: {fpath}')
        sys.exit(1)
    with open(fpath, 'r') as f:
        text = f.read()
    print(text)
    print(f'\nContent hash: {content_hash(text)}')


def cmd_update(fpath, summary, keywords, related=None):
    """Update a single entry in the index."""
    if not os.path.isfile(fpath):
        print(f'Error: file not found: {fpath}')
        sys.exit(1)
    index = load_index()
    with open(fpath, 'r') as f:
        text = f.read()
    index['entries'][fpath] = {
        'source_path': fpath,
        'content_hash': content_hash(text),
        'summary': summary,
        'keywords': keywords,
        'related': related or [],
    }
    save_index(index)
    print(f'Indexed: {fpath} ({len(keywords)} keywords)')


def cmd_search(query):
    """Search by keyword overlap with query terms. Prints ranked results."""
    index = load_index()
    query_terms = set(query.lower().split())
    results = []

    for fpath, entry in index['entries'].items():
        entry_terms = set(k.lower() for k in entry.get('keywords', []))
        summary_terms = set(entry.get('summary', '').lower().split())
        # Keywords match at full weight, summary terms at half weight
        kw_overlap = len(query_terms & entry_terms)
        summary_overlap = len(query_terms & summary_terms) * 0.5
        score = kw_overlap + summary_overlap
        if score > 0:
            results.append((score, fpath, entry))

    results.sort(key=lambda x: -x[0])

    if not results:
        print(f'No matches for: {query}')
        return []

    print(f'Results for: {query}\n')
    for score, fpath, entry in results[:10]:
        print(f'  [{score:.1f}] {fpath}')
        print(f'        {entry.get("summary", "")[:100]}')
        matched = query_terms & set(k.lower() for k in entry.get('keywords', []))
        if matched:
            print(f'        matched keywords: {", ".join(sorted(matched))}')
        print()

    return results


def cmd_search_json(query, top_n=10):
    """Search and return structured JSON for subagent reranking."""
    index = load_index()
    query_terms = set(query.lower().split())
    results = []

    for fpath, entry in index['entries'].items():
        entry_terms = set(k.lower() for k in entry.get('keywords', []))
        summary_terms = set(entry.get('summary', '').lower().split())
        kw_overlap = len(query_terms & entry_terms)
        summary_overlap = len(query_terms & summary_terms) * 0.5
        score = kw_overlap + summary_overlap
        if score > 0:
            results.append((score, fpath, entry))

    results.sort(key=lambda x: -x[0])

    candidates = []
    for score, fpath, entry in results[:top_n]:
        matched_kw = sorted(query_terms & set(k.lower() for k in entry.get('keywords', [])))
        candidates.append({
            'path': fpath,
            'keyword_score': score,
            'summary': entry.get('summary', ''),
            'keywords': entry.get('keywords', []),
            'matched_keywords': matched_kw,
            'related': entry.get('related', []),
        })

    output = {
        'query': query,
        'query_terms': sorted(query_terms),
        'candidate_count': len(candidates),
        'candidates': candidates,
    }
    print(json.dumps(output, indent=2))
    return output


def cmd_miss(query, expected_path, reason=''):
    """Log a search miss for evaluation."""
    try:
        with open(MISS_LOG_FILE, 'r') as f:
            log = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        log = []

    log.append({
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'query': query,
        'expected_path': expected_path,
        'reason': reason,
    })
    os.makedirs(os.path.dirname(MISS_LOG_FILE), exist_ok=True)
    with open(MISS_LOG_FILE, 'w') as f:
        json.dump(log, f, indent=2)
    print(f'Logged miss: query=\'{query}\' expected=\'{expected_path}\'')


def cmd_misses():
    """Print the miss log for review."""
    try:
        with open(MISS_LOG_FILE, 'r') as f:
            log = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        print('No misses logged yet.')
        return

    print(f'Miss log: {len(log)} entries\n')
    for entry in log:
        print(f'  [{entry.get("timestamp", "?")[:10]}] query: {entry["query"]}')
        print(f'    expected: {entry["expected_path"]}')
        if entry.get('reason'):
            print(f'    reason: {entry["reason"]}')
        print()


def cmd_stats():
    """Print index statistics."""
    index = load_index()
    entries = index.get('entries', {})
    total_files = len(vault_files())
    indexed = len(entries)

    all_keywords = set()
    for entry in entries.values():
        all_keywords.update(k.lower() for k in entry.get('keywords', []))

    # Check for stale entries (files that were deleted)
    stale = [p for p in entries if not os.path.isfile(p)]

    print(f'Vault files:      {total_files}')
    print(f'Indexed:          {indexed}')
    print(f'Unique keywords:  {len(all_keywords)}')
    if stale:
        print(f'Stale entries:    {len(stale)} (indexed file no longer exists)')
    if all_keywords:
        sample = sorted(all_keywords)[:20]
        print(f'Sample keywords:  {", ".join(sample)}')

    # Miss log stats
    try:
        with open(MISS_LOG_FILE, 'r') as f:
            misses = json.load(f)
        print(f'Logged misses:    {len(misses)}')
    except (FileNotFoundError, json.JSONDecodeError):
        pass


# ---------------------------------------------------------------------------
# CLI entry point
# ---------------------------------------------------------------------------

USAGE = """\
Usage: index-vault.py <command> [args]

Commands:
  scan                              Find files needing indexing
  file <path>                       Print file content + hash
  search <query>                    Search by keyword overlap
  search-json <query>               Search with JSON output for reranking
  update <path> <summary> <kw-csv>  Update index entry
  miss <query> <expected> [reason]  Log a search miss
  misses                            Show miss log
  stats                             Show index statistics
"""

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print(USAGE)
        sys.exit(1)

    cmd = sys.argv[1]

    if cmd == 'scan':
        cmd_scan()
    elif cmd == 'file':
        if len(sys.argv) < 3:
            print('Usage: index-vault.py file <path>')
            sys.exit(1)
        cmd_file(sys.argv[2])
    elif cmd == 'search':
        if len(sys.argv) < 3:
            print('Usage: index-vault.py search <query>')
            sys.exit(1)
        cmd_search(' '.join(sys.argv[2:]))
    elif cmd == 'search-json':
        if len(sys.argv) < 3:
            print('Usage: index-vault.py search-json <query>')
            sys.exit(1)
        cmd_search_json(' '.join(sys.argv[2:]))
    elif cmd == 'update':
        if len(sys.argv) < 5:
            print('Usage: index-vault.py update <path> <summary> <keywords-csv> [related-csv]')
            sys.exit(1)
        fpath = sys.argv[2]
        summary = sys.argv[3]
        keywords = [k.strip() for k in sys.argv[4].split(',')]
        related = [r.strip() for r in sys.argv[5].split(',')] if len(sys.argv) > 5 else []
        cmd_update(fpath, summary, keywords, related)
    elif cmd == 'miss':
        if len(sys.argv) < 4:
            print('Usage: index-vault.py miss <query> <expected-path> [reason]')
            sys.exit(1)
        cmd_miss(sys.argv[2], sys.argv[3], sys.argv[4] if len(sys.argv) > 4 else '')
    elif cmd == 'misses':
        cmd_misses()
    elif cmd == 'stats':
        cmd_stats()
    else:
        print(f'Unknown command: {cmd}')
        print(USAGE)
        sys.exit(1)
